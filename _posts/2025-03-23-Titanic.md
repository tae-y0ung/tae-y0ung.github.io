---
layout: post
title: "타이타닉 탑승객들의 생존 여부"
date: 2025-03-24
categories: [머신러닝, 5주차]
---



# 1912년 타이타닉 탑승객들의 생존 여부를 예측하는 머신러닝 모델 구축



```python
import numpy as np 
import pandas as pd 

# seaborn은 데이터 시각화를 위한 라이브러리로 Matplotlib을 기반으로 작동한다. 통계적 그래프를 쉽게 생성할 수 있다.
import seaborn as sns

# Matplotlib의 하위 모듈로 저수준의 시각화 도구 제공. (선 그래프, 산점도, 막대 그래프 등)
import matplotlib.pyplot as plt
```

분석 및 시각화 작업을 위해 필수적인 도구 세트를 초기화하는 단계로,  
이 라이브러리들은 이후 데이터를 불러오고, 처리하며, 그래프로 시각화하는 과정에서 중요한 역할을 한다.  
  
Seaborn과 Matplotlib은 목적, 역할, 시각화 스타일, 기능 및 접근성, 통계적 시각화에서 큰 차이가 있다.  
쉽게 말하자면 간단하고 통계적 시각화가 필요하다면 Seaborn을 쓰는 것이 적합하고, 세밀한 제어와 맞춤형 플롯을 사용하기 위해서는 Matplotlib를 사용하는 것이 적합하다.  
아래 코드에서는 심플한 막대 차트를 생성할 때 Seaborn을 사용하였고, 파이 차트를 생성할 때 Matplotlib을 이용했다. Matplotlib의 pyplot 모듈에서 plt.pie() 함수를 사용하여 파이차트를 그렸다는 걸 아래 코드를 확인하면 이해할 수 있다.



```python
# 실행 중 나타나는 경고 메세지를 숨긴다.
import warnings
warnings.filterwarnings('ignore')
```
모델 학습이나 데이터 전처리 단계에서 경고 메시지는 치명적인 오류가 아닌 경우에도 화면에 출력될 수 있기에 이를 방지하기 위해 숨긴다.  
  
이 과정을 통해 콘솔 출력을 간결하게 유지하고 중요한 정보를 더 잘 확인할 수 있다.  
하지만 경고를 무시하게 되면 중요한 문제를 간과할 위험이 있으므로 비교적 간단한 작업에만 이를 활용해야한다.



```python
# Pandas의 read_csv() 함수를 이용해서 Kaggle 경로에 저장된 csv 파일을 읽어들여 데이터 프레임 객체로 변환한다.
# 이때 해당 데이터를 df(dataframe)으로 표기한다.
train_df = pd.read_csv('/kaggle/input/titanic/train.csv')
test_df = pd.read_csv('/kaggle/input/titanic/test.csv')

# head() 메서드를 사용하여 train_df 데이터프레임의 상위 5개 행을 출력한다. 
train_df.head()
```
1. Survived : 생존 여부(0=사망, 1=생존)
2. Pclass : 객실 등급(1=1등석, 2=2등석, 3=3등석)
3. Sex, Age : 성별, 나이
4. SibSp, Parch : 동반 탑승한 가족 관계(형제/배우자 및 부모/자식 수)
5. Fare : 승선 요금



```python
# plt.subplots() : Metplotlib을 사용하여 하나의 행(row)과 두 개의 열(column)로 구성된 서브플롯을 생성한다.
# 이때 fig는 전체 Figure 객체를 나타내고, ax는 각각의 서브플롯을 담은 배열이다.

fig, ax=plt.subplots(1,2,figsize=(12,5))

# train_df['Survived'].value_counts() : Survived 열의 값을 세어서 생존자(1),사망자(0)의 빈도를 계산한다.
# .plot.pie() : 파이 차트를 생성한다.

train_df['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)

# explode=[0,0.1] : 두 번째 조각(생존자 의미)을 약간 띄워 강조한다.
# autopct='%1.1f%%' : 각 조각의 비율을 퍼센트로 표시한다. (소수점 한 자리까지)
# ax=ax[0] : 첫 번째 서브플롯(ax[0])에 차트를 그린다.
# shadow=True : 파이 차트에 그림자를 추가해 입체감을 준다.

ax[0].set_title('Survived') # 첫 번째 서브플롯의 제목을 'Survived'로 설정
ax[0].set_ylabel('') # Y축 레이블을 제거하여 그래프를 더 깔끔하게 만든다.

# Seaborn 라이브러리를 사용해 Survived 열의 카운트를 나타내는 막대 차트를 생성한다.

sns.countplot(x='Survived',data=train_df,ax=ax[1]) 

# x='Survived' : x축에 Survived(0 또는 1, 사망자 또는 생존자)을 설정한다.
# data=train_df : 데이터로 train_df를 사용한다.
# ax=ax[1] : 두 번째 서브플롯(ax[1])에 차트를 그린다.

ax[1].set_title('Survived') # 두 번째 서브플롯의 제목을 'Survived'로 설정한다.
plt.show() 
```
![Image](https://github.com/user-attachments/assets/6fe09fb6-06d3-4f91-ae71-3ac9c5124e46)
1. 첫 번째 서브플롯에서는 파이 차트를 통해 생존자와 사망자의 비율을 시각적으로 확인할 수 있다.   
(사망자 61.6%, 생존자 38.4%)
2. 두 번째 서브플롯에서는 막대 차트를 통해 생존 여부(0=사망, 1=생존)의 정확한 빈도(개수)를 확인할 수 있다.



```python
# 위에서 사용했던 코드와 같은 유형으로 Figure 크기만 가로 18, 세로 8인치로 바뀌었다.
# ax는 두 개의 서브플롯을 담은 배열이며, 각각 ax[0](남성)과 ax[1](여성)에 접근할 수 있다.
fig,ax=plt.subplots(1,2,figsize=(18,8))

# 성별이 male인 데이터만 선택한 후 Survived 열의 값(0=사망, 1=생존)의 빈도를 계산하여 파이 차트로 시각화한다.
train_df['Survived'][train_df['Sex']=='male'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)

# 앞선 남성의 생존 여부 분석과 동일하지만, 성별 조건이 female로 바뀌었으며 이는 두 번째 서브플롯에 그려진다.
train_df['Survived'][train_df['Sex']=='female'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[1],shadow=True)
ax[0].set_title('Survived (male)')
ax[1].set_title('Survived (female)')
plt.show()
```
![Image](https://github.com/user-attachments/assets/358f8b96-3448-4ca1-bbe9-07a5f66dbfb8)
1. 왼쪽의 서브플롯에서는 남성의 생존 및 사망 비율을 파이 차트로 확인할 수 있다.  
2. 오른쪽의 서브플롯에서는 여성의 생존 및 사망 비율을 파이 차트로 확인할 수 있다.  
- 타이타닉 데이터셋에서는 여성의 생존률이 높게 나타나는 경향이 보인다.  



```python
# [train_df['Sex'],train_df['Survived']] : 교차표의 행 인덱스. 성별과 생존 여부를 조합한 값
# train_df['Pclass'] : 교차표의 열 인덱스. 객실 등급(1등석, 2등석, 3등석)을 기준으로 데이터를 나눈다.
# margins=True : 행과 열의 합계를 계산해 교차표에 추가한다.
# .style.backgound_gradient(cmap='summer_r') : 교차표에 그라데이션 색상을 적용해 값의 크기를 시각적으로 강조한다.
# summer_r (뒤집힌 팔레트) : 밝은 노란색에서 짙은 녹색까지 색상 변화를 표현한다.

pd.crosstab([train_df['Sex'],train_df['Survived']],train_df['Pclass'],margins=True).style.background_gradient(cmap='summer_r')
```
교차표는 데이터의 여러 범주 간 빈도 또는 집계를 계산하는 표다.  
여기서는 성별(Sex)과 생존 여부(Survived)를 행(row)으로, 객실 등급(Pclass)을 열(column)로 설정하여 빈도를 계산한다.  
스타일링을 통해 데이터 값의 크기가 시각적으로 표현되어 직관적으로 이해하는 데 도움을 준다.


```python
# 총 2행(row), 2열(column)의 서브플롯(그래프)를 생성한다. 
# 이때 ax는 2x2 배열 형태로 서브플롯 객체를 담고 있다.
fig, ax = plt.subplots(2, 2, figsize=(20,15))

# 첫 번째 서브플롯
# sns.countplot() : Embarked 열의 각 값(S,C,Q)에 따라 탑승 승객의 개수를 막대 그래프로 표시한다.
# X축에는 탑승 항구(S,C,Q)가 표시되고, Y축에는 각 항구에서 탑승한 승객 수가 표시된다.
sns.countplot(x='Embarked', data=train_df,ax=ax[0,0])
ax[0,0].set_title('No. Of Passengers Boarded')

# 두 번째 서브플롯
# 각 항구에서 남성, 여성의 수를 색깔로 구분해 표시한다. (hue : 색깔을 의미, 데이터를 구분 기준으로 색상을 통해 구분하는 기능)
# 각 항구에서의 남성과 여성의 비율을 비교할 수 있다.
sns.countplot(x='Embarked',hue='Sex',data=train_df,ax=ax[0,1])
ax[0,1].set_title('Male-Female Split for Embarked')

# 세 번째 서브플롯
# 생존 여부를 기준으로 각 항구에서의 생존자와 사망자의 분포를 색깔로 구분한다. (hue 이용)
# 각 항구에서의 생존률을 비교할 수 있다.
sns.countplot(x='Embarked',hue='Survived',data=train_df,ax=ax[1,0])
ax[1,0].set_title('Embarked vs Survived')

# 네 번째 서브플롯
# 객실의 등급을 기준으로 각 항구에서 탑승한 승객의 등급 분포를 색을 활용하여 구분한다.
sns.countplot(x='Embarked',hue='Pclass',data=train_df,ax=ax[1,1])
ax[1,1].set_title('Embarked vs Pclass')

# 그래프 출력
plt.show()
```
![Image](https://github.com/user-attachments/assets/a821bce3-5633-4f61-a865-19d18eb4aeed)
1. 각 항구에서 탑승한 승객의 수 확인
2. 항구별 성별 분포 확인
3. 항구별 생존 여부 비교
4. 항구별 객실 등급 분포 확인



```python
# isnull() : 각 열(column)의 데이터 값이 NaN(결측값)인지 확인하며, True 값을 반환하여 결측값 식별
# 각 열에 존재하는 결측값의 개수 계산
train_df.isnull().sum()

# Embarked 열의 결측값을 'S'로 채운다. 
train_df['Embarked'].fillna('S',inplace=True)
train_df['Age'].fillna(train_df['Age'].median(), inplace=True)
train_df.drop(columns=['Cabin'], inplace=True)
```
이는 결측값을 찾고, 처리하는 코드로 train_df.isnull().sum() 이 코드를 통해 데이터셋에서 어떤 열에 결측값이 있는지 확인을 먼저 한다.  
이 경우에선 Age에 177개, Cabin에 687개, Embarked 열에 2개의 결측값이 존재했다.  
Embarked의 결측값을 제거하지 않고 S로 채웠는데 그 이유는 대부분의 승객이 S(탑승 항구)에서 탑승했기 때문이다.  
공부를 하던 중 나이는 중위값으로, Cabin의 결측치는 제거해주는 방식도 고려하게 되어 수정해보았는데 Embarked에 비해 해당 값들이 결측값이 많았음에도 정확도에는 큰 영향을 주지 않았다. 상대적으로 약한 상관관계를 가지고 있었다고 판단할 수 있었다. 



```python
from sklearn.tree import DecisionTreeClassifier  # 결정 트리 모델을 사용하여 생존 여부 예측
from sklearn.model_selection import train_test_split  # 데이터를 학습용과 테스트용으로 분리
from sklearn.preprocessing import OneHotEncoder  # 범주형 데이터를 숫자로 변환
from sklearn import metrics  # 정확도 계산에 이용

# train_df을 학습 데이터(70%)와 테스트 데이터(30%)로 랜덤하게 분리
# random_state=0 으로 설정해 재현 가능한 결과 얻기 
train, test = train_test_split(train_df, test_size=0.3, random_state=0) 

target_col = ['Pclass', 'Sex', 'Embarked'] # 주요 변수 정의
train_X = train[target_col]
train_Y = train['Survived']
test_X = test[target_col]
test_Y = test['Survived']

# 결측값 처리 (앞의 값 채우기 방식, forward fill)
train_X = train_X.fillna(method='ffill')
test_X = test_X.fillna(method='ffill')

# 범주형 데이터를 숫자형 데이터로 변환 (원-핫 인코딩 이용)
encoder = OneHotEncoder(sparse=False)
train_X_encoded = encoder.fit_transform(train_X)  # 학습 데이터에서 인코더를 학습하며 변환
test_X_encoded = encoder.transform(test_X)  # 이미 학습된 인코더를 사용하여 테스트 데이터 변환

# 결정 트리 모델 학습
tree_model = DecisionTreeClassifier()
tree_model.fit(train_X_encoded, train_Y.values)

# 정확도 계산
dt_prediction = tree_model.predict(test_X_encoded)  # 테스트 데이터를 기반으로 생존 여부 예측
print('The accuracy of the Decision Tree is', metrics.accuracy_score(test_Y, dt_prediction))  # 테스트 데이터에 대한 모델의 정확도 계산

# 테스트 데이터 예측
test_features_encoded = encoder.transform(test_df[target_col])
```
Kaggle 제출용 테스트 데이터를 인코딩하여 학습시킨 모델에 전달하면 방금까지 학습한 결정 트리 모델이 테스트 데이터의 생존 여부를 예측한다.  
해당 과정에서 random_state=0으로 고정하였는데 공부하던 중 이전까지 했던 방식처럼 random_state=42로 고정해보면 값이 달라질까 궁금하여 실제로 42로 진행해보았다.  
이제까지 했던 자료들에 비해 예측하기 쉬운 샘플이어서 그런지 오히려 random_state=42로 분할하였을 때 정확도가 1% 정도 떨어진다는 걸 알 수 있었다.


```python
# 제출 파일 생성
dt_prediction_result = tree_model.predict(test_features_encoded)

PassengerId = np.array(test_df["PassengerId"]).astype(int)  # 테스트 데이터에서 승객 ID를 추출한다.
Survived = dt_prediction_result  
submission = pd.DataFrame({
    "PassengerId": PassengerId,
    "Survived": Survived
})  # 예측 결과를 제출 형식에 맞추어 두 열(PassengerId, Survived)로 구성된 데이터 프레임을 생성한다.

submission.to_csv("submission.csv", index=False)  # submission.csv로 저장한다.
```
이 부분이 굉장히 중요한데, 처음 Kaggle을 이용하는 사람은 csv 파일로 제출해야 한다는 점을 간과할 수 있기 때문이다.  
실제로 제출 파일을 따로 생성하지 않으면 *'submission file not found'* 이러한 오류가 뜨게 된다.


해결 방법으로는 
```python
import os
print(os.listdir())  # 현재 작업 디렉토리(CWD) 안에 있는 모든 파일과 디렉토리의 이름을 리스트 형태로 반환한다.
```
현재 작업 디렉토리의 파일 목록을 출력하는 방법과

```python
submission.to_csv("submission.csv", index=False)  # 저장된 CSV 파일에서 인덱스를 저장할 필요가 없을 때 index=False를 이용한다.
```
저장 경로를 확인하고, /kaggle/working/이므로, 파일이 이 디렉토리에 있는지 확인하는 방법이 있다.  

마지막으로는 제출 파일을 생성하는 코드가 제대로 작성이 되지 않거나 데이터프레임이 비어 있을 수 있으니 아래 코드를 활용해 데이터 프레임이 비어 있는지 확인하는 것도 좋은 방법이다.

```python
submission = pd.DataFrame({"PassengerId": test_df["PassengerId"], "Survived": y_pred})  # Titanic 생존자 예측 모델의 결과를 제출용 데이터 프레임으로 준비하는 과정이다.
print(submission.head())
```


